{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2034d4b3",
   "metadata": {},
   "source": [
    "# Hierarchical Data Generator Analysis\n",
    "\n",
    "This notebook demonstrates the generation and analysis of hierarchical sparse data using two different tree configurations:\n",
    "\n",
    "1. **Simple Hierarchy**: A basic two-level tree structure with hierarchical dependencies\n",
    "2. **Exclusive Groups**: A tree structure with mutually exclusive children \n",
    "\n",
    "We'll generate synthetic datasets for both configurations and create comprehensive visualizations including:\n",
    "- Feature activation patterns\n",
    "- Data vector representations  \n",
    "- Feature direction vectors\n",
    "- Statistical properties and dependencies\n",
    "\n",
    "The analysis showcases how different tree structures create distinct patterns in the generated data, which can be used to test Sparse Autoencoders (SAEs) under various hierarchical constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a7b73a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8cc3230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/cy/1jgnhtk91d144tb0kyh6jrl80000gn/T/ipykernel_30075/2788948471.py\", line 2, in <module>\n",
      "    import torch\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10d6133d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "\n",
    "# Import our custom modules\n",
    "sys.path.append(\"/Users/kkumbier/github/matryoshka-saes/\")\n",
    "from data_generator import HierarchicalDataGenerator\n",
    "from toy_model import Tree, TreeDataset\n",
    "from heatmap import heatmap\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cab4a05",
   "metadata": {},
   "source": [
    "## 2. Load Tree Configurations\n",
    "\n",
    "We'll load the two tree configurations we want to analyze:\n",
    "- **Simple Hierarchy**: A basic hierarchical structure with standard parameters\n",
    "- **Exclusive Groups**: A configuration with mutually exclusive feature groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25d72a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configurations:\n",
      "{\n",
      "  \"exclusive_groups\": {\n",
      "    \"tree_config\": \"/Users/kkumbier/github/matryoshka-saes/tree_params/exclusive_groups.json\",\n",
      "    \"d_model\": 128,\n",
      "    \"feature_correlation\": 0.1,\n",
      "    \"noise_level\": 0.02,\n",
      "    \"orthogonal_features\": true,\n",
      "    \"feature_scale_variation\": 0.1,\n",
      "    \"random_seed\": 123\n",
      "  },\n",
      "  \"simple_hierarchy\": {\n",
      "    \"tree_config\": \"/Users/kkumbier/github/matryoshka-saes/tree_params/simple_hierarchy.json\",\n",
      "    \"d_model\": 256,\n",
      "    \"feature_correlation\": 0.0,\n",
      "    \"noise_level\": 0.0,\n",
      "    \"orthogonal_features\": true,\n",
      "    \"feature_scale_variation\": 0.05,\n",
      "    \"random_seed\": 42\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Define the tree parameter directory\n",
    "tree_params_dir = \"/Users/kkumbier/github/matryoshka-saes/tree_params\"\n",
    "\n",
    "# Load the two configurations we want to analyze\n",
    "configs = {}\n",
    "\n",
    "# Load exclusive groups configuration (full parameters)\n",
    "with open(os.path.join(tree_params_dir, \"exclusive_params.json\"), 'r') as f:\n",
    "    configs['exclusive_groups'] = json.load(f)\n",
    "\n",
    "# Load simple hierarchy configuration (full parameters)  \n",
    "with open(os.path.join(tree_params_dir, \"simple_params.json\"), 'r') as f:\n",
    "    configs['simple_hierarchy'] = json.load(f)\n",
    "\n",
    "for name, config in configs.items():\n",
    "    configs[name][\"tree_config\"] = os.path.join(\n",
    "        tree_params_dir, config[\"tree_config\"]\n",
    "    )\n",
    "    \n",
    "print(\"Loaded configurations:\")\n",
    "print(json.dumps(configs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d12231",
   "metadata": {},
   "source": [
    "## 3. Generate Datasets for Both Configurations\n",
    "\n",
    "Now we'll create HierarchicalDataGenerator instances for each configuration and generate sample datasets to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "960d50a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      2\u001b[39m generator = HierarchicalDataGenerator(**configs[\u001b[33m\"\u001b[39m\u001b[33mexclusive_groups\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      3\u001b[39m dataset = generator.create_dataset(\n\u001b[32m      4\u001b[39m     batch_size=\u001b[32m10\u001b[39m, num_batches=\u001b[32m1000\u001b[39m, device=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/matryoshka-saes/toy_model.py:120\u001b[39m, in \u001b[36mTreeDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     true_acts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# random_scale = 1+torch.randn_like(true_acts, device=self.true_feats.device) * 0.05\u001b[39;00m\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# true_acts = true_acts * random_scale\u001b[39;00m\n\u001b[32m    123\u001b[39m     x = true_acts @ \u001b[38;5;28mself\u001b[39m.true_feats\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/matryoshka-saes/toy_model.py:67\u001b[39m, in \u001b[36mTree.sample\u001b[39m\u001b[34m(self, shape, force_inactive, force_active)\u001b[39m\n\u001b[32m     65\u001b[39m         shape = (shape,)\n\u001b[32m     66\u001b[39m     n_samples = np.prod(shape)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     samples = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.tensor(samples).view(*shape, -\u001b[32m1\u001b[39m).float()\n\u001b[32m     70\u001b[39m sample = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/matryoshka-saes/toy_model.py:67\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     65\u001b[39m         shape = (shape,)\n\u001b[32m     66\u001b[39m     n_samples = np.prod(shape)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     samples = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_samples)]\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.tensor(samples).view(*shape, -\u001b[32m1\u001b[39m).float()\n\u001b[32m     70\u001b[39m sample = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/matryoshka-saes/toy_model.py:102\u001b[39m, in \u001b[36mTree.sample\u001b[39m\u001b[34m(self, shape, force_inactive, force_active)\u001b[39m\n\u001b[32m     94\u001b[39m     child_force_inactive = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(is_active) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m     95\u001b[39m         \u001b[38;5;28mself\u001b[39m.mutually_exclusive_children \u001b[38;5;129;01mand\u001b[39;00m child != active_child\n\u001b[32m     96\u001b[39m     )\n\u001b[32m     98\u001b[39m     child_force_active = (\n\u001b[32m     99\u001b[39m         \u001b[38;5;28mself\u001b[39m.mutually_exclusive_children \u001b[38;5;129;01mand\u001b[39;00m child == active_child\n\u001b[32m    100\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     sample += \u001b[43mchild\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_inactive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchild_force_inactive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_active\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchild_force_active\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m sample\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/matryoshka-saes/toy_model.py:88\u001b[39m, in \u001b[36mTree.sample\u001b[39m\u001b[34m(self, shape, force_inactive, force_active)\u001b[39m\n\u001b[32m     84\u001b[39m         sample.append((is_active * torch.rand(\u001b[32m1\u001b[39m)))\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mutually_exclusive_children:\n\u001b[32m     87\u001b[39m     active_child = (\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m         \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchildren\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchild_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m is_active\n\u001b[32m     90\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     91\u001b[39m     )\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children:\n\u001b[32m     94\u001b[39m     child_force_inactive = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(is_active) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m     95\u001b[39m         \u001b[38;5;28mself\u001b[39m.mutually_exclusive_children \u001b[38;5;129;01mand\u001b[39;00m child != active_child\n\u001b[32m     96\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy/random/mtrand.pyx:980\u001b[39m, in \u001b[36mnumpy.random.mtrand.RandomState.choice\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/torch/_tensor.py:1064\u001b[39m, in \u001b[36mTensor.__array__\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.numpy()\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy\n",
    "generator = HierarchicalDataGenerator(**configs[\"exclusive_groups\"])\n",
    "dataset = generator.create_dataset(\n",
    "    batch_size=10, num_batches=1000, device=\"cpu\"\n",
    ")\n",
    "\n",
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71a1e11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating dataset for exclusive_groups...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m generators[name] = generator\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Generate a dataset\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m X, feature_activations = generator.create_dataset()\n\u001b[32m     16\u001b[39m datasets[name] = {\n\u001b[32m     17\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mX\u001b[39m\u001b[33m'\u001b[39m: X,\n\u001b[32m     18\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfeature_activations\u001b[39m\u001b[33m'\u001b[39m: feature_activations,\n\u001b[32m     19\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mgenerator\u001b[39m\u001b[33m'\u001b[39m: generator\n\u001b[32m     20\u001b[39m }\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Generated data shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/matryoshka-saes/toy_model.py:120\u001b[39m, in \u001b[36mTreeDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     true_acts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# random_scale = 1+torch.randn_like(true_acts, device=self.true_feats.device) * 0.05\u001b[39;00m\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# true_acts = true_acts * random_scale\u001b[39;00m\n\u001b[32m    123\u001b[39m     x = true_acts @ \u001b[38;5;28mself\u001b[39m.true_feats\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/matryoshka-saes/toy_model.py:67\u001b[39m, in \u001b[36mTree.sample\u001b[39m\u001b[34m(self, shape, force_inactive, force_active)\u001b[39m\n\u001b[32m     65\u001b[39m         shape = (shape,)\n\u001b[32m     66\u001b[39m     n_samples = np.prod(shape)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     samples = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.tensor(samples).view(*shape, -\u001b[32m1\u001b[39m).float()\n\u001b[32m     70\u001b[39m sample = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/matryoshka-saes/toy_model.py:67\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     65\u001b[39m         shape = (shape,)\n\u001b[32m     66\u001b[39m     n_samples = np.prod(shape)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     samples = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_samples)]\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.tensor(samples).view(*shape, -\u001b[32m1\u001b[39m).float()\n\u001b[32m     70\u001b[39m sample = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/matryoshka-saes/toy_model.py:102\u001b[39m, in \u001b[36mTree.sample\u001b[39m\u001b[34m(self, shape, force_inactive, force_active)\u001b[39m\n\u001b[32m     94\u001b[39m     child_force_inactive = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(is_active) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m     95\u001b[39m         \u001b[38;5;28mself\u001b[39m.mutually_exclusive_children \u001b[38;5;129;01mand\u001b[39;00m child != active_child\n\u001b[32m     96\u001b[39m     )\n\u001b[32m     98\u001b[39m     child_force_active = (\n\u001b[32m     99\u001b[39m         \u001b[38;5;28mself\u001b[39m.mutually_exclusive_children \u001b[38;5;129;01mand\u001b[39;00m child == active_child\n\u001b[32m    100\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     sample += \u001b[43mchild\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_inactive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchild_force_inactive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_active\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchild_force_active\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m sample\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/matryoshka-saes/toy_model.py:88\u001b[39m, in \u001b[36mTree.sample\u001b[39m\u001b[34m(self, shape, force_inactive, force_active)\u001b[39m\n\u001b[32m     84\u001b[39m         sample.append((is_active * torch.rand(\u001b[32m1\u001b[39m)))\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mutually_exclusive_children:\n\u001b[32m     87\u001b[39m     active_child = (\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m         \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchildren\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchild_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m is_active\n\u001b[32m     90\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     91\u001b[39m     )\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children:\n\u001b[32m     94\u001b[39m     child_force_inactive = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(is_active) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m     95\u001b[39m         \u001b[38;5;28mself\u001b[39m.mutually_exclusive_children \u001b[38;5;129;01mand\u001b[39;00m child != active_child\n\u001b[32m     96\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy/random/mtrand.pyx:980\u001b[39m, in \u001b[36mnumpy.random.mtrand.RandomState.choice\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/torch/_tensor.py:1064\u001b[39m, in \u001b[36mTensor.__array__\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.numpy()\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "# Create generators for both configurations\n",
    "generators = {}\n",
    "datasets = {}\n",
    "feature_directions = {}\n",
    "\n",
    "for name, config in configs.items():\n",
    "    print(f\"\\nGenerating dataset for {name}...\")\n",
    "    \n",
    "    # Create the generator\n",
    "    generator = HierarchicalDataGenerator(**config)\n",
    "    generators[name] = generator\n",
    "\n",
    "    # Generate a dataset\n",
    "    X, feature_activations = generator.create_dataset()\n",
    "    \n",
    "    datasets[name] = {\n",
    "        'X': X,\n",
    "        'feature_activations': feature_activations,\n",
    "        'generator': generator\n",
    "    }\n",
    "    \n",
    "    print(f\"  Generated data shape: {X.shape}\")\n",
    "    print(f\"  Number of feature types: {len(feature_activations)}\")\n",
    "    print(f\"  Feature activation shapes: {[f'Level {i}: {act.shape}' for i, act in enumerate(feature_activations)]}\")\n",
    "    \n",
    "    # # Store feature directions for analysis\n",
    "    # feature_directions[name] = {\n",
    "    #     'orthogonal': generator.orthogonal_directions,\n",
    "    #     'correlated': generator.correlated_directions if hasattr(generator, 'correlated_directions') else None\n",
    "    # }\n",
    "\n",
    "print(\"\\nDataset generation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d0c024",
   "metadata": {},
   "source": [
    "## 4. Data Visualization: Generated Dataset Heatmaps\n",
    "\n",
    "Let's visualize the generated data matrices to understand the overall structure and patterns in our hierarchical datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e733a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmaps for generated data\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "for idx, (name, data) in enumerate(datasets.items()):\n",
    "    X = data['X'].detach().numpy() if torch.is_tensor(data['X']) else data['X']\n",
    "    \n",
    "    # Create heatmap\n",
    "    im = axes[idx].imshow(X[:50].T, aspect='auto', cmap='RdBu_r', interpolation='nearest')\n",
    "    axes[idx].set_title(f'{name.replace(\"_\", \" \").title()} - Generated Data\\n(First 50 samples)', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Sample Index')\n",
    "    axes[idx].set_ylabel('Feature Dimension')\n",
    "    \n",
    "    # Add colorbar\n",
    "    plt.colorbar(im, ax=axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print data statistics\n",
    "print(\"\\nData Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "for name, data in datasets.items():\n",
    "    X = data['X'].detach().numpy() if torch.is_tensor(data['X']) else data['X']\n",
    "    print(f\"\\n{name.upper()}:\")\n",
    "    print(f\"  Shape: {X.shape}\")\n",
    "    print(f\"  Mean: {X.mean():.4f}\")\n",
    "    print(f\"  Std: {X.std():.4f}\")\n",
    "    print(f\"  Min: {X.min():.4f}\")\n",
    "    print(f\"  Max: {X.max():.4f}\")\n",
    "    print(f\"  Non-zero elements: {np.count_nonzero(X)} / {X.size} ({100 * np.count_nonzero(X) / X.size:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99279885",
   "metadata": {},
   "source": [
    "## 5. Feature Activation Analysis\n",
    "\n",
    "Now let's examine the hierarchical feature activations to understand how features are activated at different levels of the tree structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001f9d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature activations for both configurations\n",
    "for name, data in datasets.items():\n",
    "    feature_activations = data['feature_activations']\n",
    "    \n",
    "    print(f\"\\n{name.upper()} - Feature Activation Analysis:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create subplots for each level\n",
    "    n_levels = len(feature_activations)\n",
    "    if n_levels > 0:\n",
    "        fig, axes = plt.subplots(1, n_levels, figsize=(5 * n_levels, 6))\n",
    "        if n_levels == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for level, activations in enumerate(feature_activations):\n",
    "            if torch.is_tensor(activations):\n",
    "                activations = activations.detach().numpy()\n",
    "            \n",
    "            # Show first 50 samples for clarity\n",
    "            display_activations = activations[:50]\n",
    "            \n",
    "            im = axes[level].imshow(display_activations.T, aspect='auto', cmap='Blues', interpolation='nearest')\n",
    "            axes[level].set_title(f'Level {level} Activations\\n({activations.shape[1]} features)', fontweight='bold')\n",
    "            axes[level].set_xlabel('Sample Index')\n",
    "            axes[level].set_ylabel('Feature Index')\n",
    "            plt.colorbar(im, ax=axes[level])\n",
    "            \n",
    "            # Print statistics\n",
    "            print(f\"  Level {level}:\")\n",
    "            print(f\"    Shape: {activations.shape}\")\n",
    "            print(f\"    Active features per sample (mean): {activations.sum(axis=1).mean():.2f}\")\n",
    "            print(f\"    Activation probability per feature: {activations.mean(axis=0).mean():.4f}\")\n",
    "            print(f\"    Non-zero activations: {np.count_nonzero(activations)} / {activations.size} ({100 * np.count_nonzero(activations) / activations.size:.2f}%)\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"  No feature activations found!\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e451f7",
   "metadata": {},
   "source": [
    "## 6. Feature Direction Analysis\n",
    "\n",
    "Let's analyze the feature directions (both orthogonal and correlated) to understand the geometric structure of our feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac74727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature directions for both configurations\n",
    "for name, directions in feature_directions.items():\n",
    "    print(f\"\\n{name.upper()} - Feature Direction Analysis:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Analyze orthogonal directions\n",
    "    if directions['orthogonal'] is not None:\n",
    "        ortho_dirs = directions['orthogonal']\n",
    "        if torch.is_tensor(ortho_dirs):\n",
    "            ortho_dirs = ortho_dirs.detach().numpy()\n",
    "        \n",
    "        print(f\"Orthogonal directions shape: {ortho_dirs.shape}\")\n",
    "        \n",
    "        # Visualize orthogonal directions\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Heatmap of directions\n",
    "        plt.subplot(1, 2, 1)\n",
    "        im1 = plt.imshow(ortho_dirs.T, aspect='auto', cmap='RdBu_r', interpolation='nearest')\n",
    "        plt.title(f'{name.replace(\"_\", \" \").title()}\\nOrthogonal Feature Directions', fontweight='bold')\n",
    "        plt.xlabel('Input Dimension')\n",
    "        plt.ylabel('Feature Index')\n",
    "        plt.colorbar(im1)\n",
    "        \n",
    "        # Compute and show correlation matrix of directions\n",
    "        plt.subplot(1, 2, 2)\n",
    "        correlation_matrix = np.corrcoef(ortho_dirs)\n",
    "        im2 = plt.imshow(correlation_matrix, cmap='RdBu_r', vmin=-1, vmax=1, interpolation='nearest')\n",
    "        plt.title('Feature Direction Correlations\\n(Should be near-orthogonal)', fontweight='bold')\n",
    "        plt.xlabel('Feature Index')\n",
    "        plt.ylabel('Feature Index')\n",
    "        plt.colorbar(im2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Statistics\n",
    "        print(f\"  Direction magnitudes (mean ± std): {np.linalg.norm(ortho_dirs, axis=1).mean():.4f} ± {np.linalg.norm(ortho_dirs, axis=1).std():.4f}\")\n",
    "        \n",
    "        # Check orthogonality\n",
    "        dot_products = []\n",
    "        n_features = ortho_dirs.shape[0]\n",
    "        for i in range(n_features):\n",
    "            for j in range(i+1, n_features):\n",
    "                dot_products.append(np.dot(ortho_dirs[i], ortho_dirs[j]))\n",
    "        \n",
    "        if dot_products:\n",
    "            mean_dot = np.mean(np.abs(dot_products))\n",
    "            print(f\"  Mean absolute dot product (orthogonality check): {mean_dot:.6f} (closer to 0 = more orthogonal)\")\n",
    "        \n",
    "    # Analyze correlated directions if they exist\n",
    "    if directions['correlated'] is not None:\n",
    "        corr_dirs = directions['correlated']\n",
    "        if torch.is_tensor(corr_dirs):\n",
    "            corr_dirs = corr_dirs.detach().numpy()\n",
    "        \n",
    "        print(f\"Correlated directions shape: {corr_dirs.shape}\")\n",
    "        \n",
    "        # Similar analysis for correlated directions\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        im1 = plt.imshow(corr_dirs.T, aspect='auto', cmap='RdBu_r', interpolation='nearest')\n",
    "        plt.title(f'{name.replace(\"_\", \" \").title()}\\nCorrelated Feature Directions', fontweight='bold')\n",
    "        plt.xlabel('Input Dimension')\n",
    "        plt.ylabel('Feature Index')\n",
    "        plt.colorbar(im1)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        correlation_matrix = np.corrcoef(corr_dirs)\n",
    "        im2 = plt.imshow(correlation_matrix, cmap='RdBu_r', vmin=-1, vmax=1, interpolation='nearest')\n",
    "        plt.title('Correlated Direction Correlations', fontweight='bold')\n",
    "        plt.xlabel('Feature Index')\n",
    "        plt.ylabel('Feature Index')\n",
    "        plt.colorbar(im2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"  Correlated direction magnitudes (mean ± std): {np.linalg.norm(corr_dirs, axis=1).mean():.4f} ± {np.linalg.norm(corr_dirs, axis=1).std():.4f}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f17cb3",
   "metadata": {},
   "source": [
    "## 7. Comparative Analysis: Exclusive Groups vs Simple Hierarchy\n",
    "\n",
    "Let's compare the two configurations directly to understand their differences in structure and behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative analysis between configurations\n",
    "print(\"COMPARATIVE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compare basic properties\n",
    "config_names = list(configs.keys())\n",
    "name1, name2 = config_names[0], config_names[1]\n",
    "\n",
    "print(f\"\\nConfiguration Comparison:\")\n",
    "print(f\"{'Property':<25} {'Exclusive Groups':<20} {'Simple Hierarchy':<20}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for prop in ['input_dim', 'n_samples', 'correlation_type', 'feature_correlation']:\n",
    "    val1 = configs[name1].get(prop, 'N/A')\n",
    "    val2 = configs[name2].get(prop, 'N/A')\n",
    "    print(f\"{prop:<25} {str(val1):<20} {str(val2):<20}\")\n",
    "\n",
    "# Compare data characteristics\n",
    "print(f\"\\nData Characteristics:\")\n",
    "print(f\"{'Metric':<25} {'Exclusive Groups':<20} {'Simple Hierarchy':<20}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "data1 = datasets[name1]['X'].detach().numpy() if torch.is_tensor(datasets[name1]['X']) else datasets[name1]['X']\n",
    "data2 = datasets[name2]['X'].detach().numpy() if torch.is_tensor(datasets[name2]['X']) else datasets[name2]['X']\n",
    "\n",
    "metrics = {\n",
    "    'Data shape': [str(data1.shape), str(data2.shape)],\n",
    "    'Mean activation': [f\"{data1.mean():.4f}\", f\"{data2.mean():.4f}\"],\n",
    "    'Std activation': [f\"{data1.std():.4f}\", f\"{data2.std():.4f}\"],\n",
    "    'Sparsity (% zeros)': [f\"{100*(1-np.count_nonzero(data1)/data1.size):.1f}%\", \n",
    "                          f\"{100*(1-np.count_nonzero(data2)/data2.size):.1f}%\"]\n",
    "}\n",
    "\n",
    "for metric, values in metrics.items():\n",
    "    print(f\"{metric:<25} {values[0]:<20} {values[1]:<20}\")\n",
    "\n",
    "# Compare feature activation patterns\n",
    "print(f\"\\nFeature Activation Patterns:\")\n",
    "print(f\"{'Level':<10} {'Exclusive Groups':<30} {'Simple Hierarchy':<30}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "max_levels = max(len(datasets[name1]['feature_activations']), len(datasets[name2]['feature_activations']))\n",
    "\n",
    "for level in range(max_levels):\n",
    "    act1 = datasets[name1]['feature_activations'][level] if level < len(datasets[name1]['feature_activations']) else None\n",
    "    act2 = datasets[name2]['feature_activations'][level] if level < len(datasets[name2]['feature_activations']) else None\n",
    "    \n",
    "    if act1 is not None:\n",
    "        act1_np = act1.detach().numpy() if torch.is_tensor(act1) else act1\n",
    "        act1_desc = f\"Shape: {act1_np.shape}, Sparsity: {100*(1-np.count_nonzero(act1_np)/act1_np.size):.1f}%\"\n",
    "    else:\n",
    "        act1_desc = \"No activations\"\n",
    "        \n",
    "    if act2 is not None:\n",
    "        act2_np = act2.detach().numpy() if torch.is_tensor(act2) else act2\n",
    "        act2_desc = f\"Shape: {act2_np.shape}, Sparsity: {100*(1-np.count_nonzero(act2_np)/act2_np.size):.1f}%\"\n",
    "    else:\n",
    "        act2_desc = \"No activations\"\n",
    "    \n",
    "    print(f\"{level:<10} {act1_desc:<30} {act2_desc:<30}\")\n",
    "\n",
    "# Side-by-side visualization\n",
    "print(f\"\\nSide-by-side Data Visualization:\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Top row: raw data comparison\n",
    "for idx, (name, data) in enumerate(datasets.items()):\n",
    "    X = data['X'].detach().numpy() if torch.is_tensor(data['X']) else data['X']\n",
    "    im = axes[0, idx].imshow(X[:100].T, aspect='auto', cmap='RdBu_r', interpolation='nearest')\n",
    "    axes[0, idx].set_title(f'{name.replace(\"_\", \" \").title()}\\nGenerated Data (First 100 samples)', fontweight='bold')\n",
    "    axes[0, idx].set_xlabel('Sample Index')\n",
    "    axes[0, idx].set_ylabel('Feature Dimension')\n",
    "    plt.colorbar(im, ax=axes[0, idx])\n",
    "\n",
    "# Bottom row: feature activations (level 0 if available)\n",
    "for idx, (name, data) in enumerate(datasets.items()):\n",
    "    if len(data['feature_activations']) > 0:\n",
    "        activations = data['feature_activations'][0]\n",
    "        if torch.is_tensor(activations):\n",
    "            activations = activations.detach().numpy()\n",
    "        im = axes[1, idx].imshow(activations[:100].T, aspect='auto', cmap='Blues', interpolation='nearest')\n",
    "        axes[1, idx].set_title(f'{name.replace(\"_\", \" \").title()}\\nLevel 0 Feature Activations', fontweight='bold')\n",
    "        axes[1, idx].set_xlabel('Sample Index')\n",
    "        axes[1, idx].set_ylabel('Feature Index')\n",
    "        plt.colorbar(im, ax=axes[1, idx])\n",
    "    else:\n",
    "        axes[1, idx].text(0.5, 0.5, 'No feature activations\\navailable', \n",
    "                         ha='center', va='center', transform=axes[1, idx].transAxes, fontsize=12)\n",
    "        axes[1, idx].set_title(f'{name.replace(\"_\", \" \").title()}\\nNo Feature Activations', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mech_int",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
