{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2034d4b3",
   "metadata": {},
   "source": [
    "# Hierarchical Data Generator Analysis\n",
    "\n",
    "This notebook demonstrates the generation and analysis of hierarchical sparse data using two different tree configurations:\n",
    "\n",
    "1. **Simple Hierarchy**: A basic two-level tree structure with hierarchical dependencies\n",
    "2. **Exclusive Groups**: A tree structure with mutually exclusive children \n",
    "\n",
    "We'll generate synthetic datasets for both configurations and create comprehensive visualizations including:\n",
    "- Feature activation patterns\n",
    "- Data vector representations  \n",
    "- Feature direction vectors\n",
    "- Statistical properties and dependencies\n",
    "\n",
    "The analysis showcases how different tree structures create distinct patterns in the generated data, which can be used to test Sparse Autoencoders (SAEs) under various hierarchical constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a7b73a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8cc3230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1185e2f90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import our custom modules\n",
    "sys.path.append(\"/Users/kkumbier/github/matryoshka-saes/\")\n",
    "from data_generator import HierarchicalDataGenerator\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0ba1b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/mech_int/bin/python\n",
      "NumPy: 1.26.4\n",
      "Torch: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "import numpy as np\n",
    "print(\"NumPy:\", np.__version__)\n",
    "import torch\n",
    "print(\"Torch:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7977cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/torch/__init__.py\n",
      "/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/numpy/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "print(torch.__file__)\n",
    "print(np.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cab4a05",
   "metadata": {},
   "source": [
    "## 2. Load Tree Configurations\n",
    "\n",
    "We'll load the two tree configurations we want to analyze:\n",
    "- **Simple Hierarchy**: A basic hierarchical structure with standard parameters\n",
    "- **Exclusive Groups**: A configuration with mutually exclusive feature groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25d72a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configurations:\n",
      "{\n",
      "  \"exclusive_groups\": {\n",
      "    \"tree_config\": \"/Users/kkumbier/github/matryoshka-saes/tree_params/exclusive_groups.json\",\n",
      "    \"d_model\": 128,\n",
      "    \"feature_correlation\": 0.1,\n",
      "    \"noise_level\": 0.02,\n",
      "    \"orthogonal_features\": true,\n",
      "    \"feature_scale_variation\": 0.1,\n",
      "    \"random_seed\": 123\n",
      "  },\n",
      "  \"simple_hierarchy\": {\n",
      "    \"tree_config\": \"/Users/kkumbier/github/matryoshka-saes/tree_params/simple_hierarchy.json\",\n",
      "    \"d_model\": 256,\n",
      "    \"feature_correlation\": 0.0,\n",
      "    \"noise_level\": 0.0,\n",
      "    \"orthogonal_features\": true,\n",
      "    \"feature_scale_variation\": 0.05,\n",
      "    \"random_seed\": 42\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Define the tree parameter directory\n",
    "tree_params_dir = \"/Users/kkumbier/github/matryoshka-saes/tree_params\"\n",
    "\n",
    "# Load the two configurations we want to analyze\n",
    "configs = {}\n",
    "\n",
    "# Load exclusive groups configuration (full parameters)\n",
    "with open(os.path.join(tree_params_dir, \"exclusive_params.json\"), 'r') as f:\n",
    "    configs['exclusive_groups'] = json.load(f)\n",
    "\n",
    "# Load simple hierarchy configuration (full parameters)  \n",
    "with open(os.path.join(tree_params_dir, \"simple_params.json\"), 'r') as f:\n",
    "    configs['simple_hierarchy'] = json.load(f)\n",
    "\n",
    "\n",
    "print(\"Loaded configurations:\")\n",
    "print(json.dumps(configs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d12231",
   "metadata": {},
   "source": [
    "## 3. Generate Datasets for Both Configurations\n",
    "\n",
    "Now we'll create HierarchicalDataGenerator instances for each configuration and generate sample datasets to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "960d50a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "probabilities do not sum to 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m generator = HierarchicalDataGenerator(**configs[\u001b[33m\"\u001b[39m\u001b[33mexclusive_groups\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      2\u001b[39m dataset = generator.create_dataset(\n\u001b[32m      3\u001b[39m     batch_size=\u001b[32m5\u001b[39m, num_batches=\u001b[32m2\u001b[39m, device=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/matryoshka-saes/tree.py:120\u001b[39m, in \u001b[36mTreeDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     true_acts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m     x = true_acts @ \u001b[38;5;28mself\u001b[39m.true_feats\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/matryoshka-saes/tree.py:67\u001b[39m, in \u001b[36mTree.sample\u001b[39m\u001b[34m(self, shape, force_inactive, force_active)\u001b[39m\n\u001b[32m     65\u001b[39m         shape = (shape,)\n\u001b[32m     66\u001b[39m     n_samples = np.prod(shape)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     samples = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.tensor(samples).view(*shape, -\u001b[32m1\u001b[39m).float()\n\u001b[32m     70\u001b[39m sample = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/matryoshka-saes/tree.py:67\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     65\u001b[39m         shape = (shape,)\n\u001b[32m     66\u001b[39m     n_samples = np.prod(shape)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     samples = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_samples)]\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.tensor(samples).view(*shape, -\u001b[32m1\u001b[39m).float()\n\u001b[32m     70\u001b[39m sample = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/matryoshka-saes/tree.py:102\u001b[39m, in \u001b[36mTree.sample\u001b[39m\u001b[34m(self, shape, force_inactive, force_active)\u001b[39m\n\u001b[32m     94\u001b[39m     child_force_inactive = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(is_active) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m     95\u001b[39m         \u001b[38;5;28mself\u001b[39m.mutually_exclusive_children \u001b[38;5;129;01mand\u001b[39;00m child != active_child\n\u001b[32m     96\u001b[39m     )\n\u001b[32m     98\u001b[39m     child_force_active = (\n\u001b[32m     99\u001b[39m         \u001b[38;5;28mself\u001b[39m.mutually_exclusive_children \u001b[38;5;129;01mand\u001b[39;00m child == active_child\n\u001b[32m    100\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     sample += \u001b[43mchild\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_inactive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchild_force_inactive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_active\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchild_force_active\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m sample\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/matryoshka-saes/tree.py:88\u001b[39m, in \u001b[36mTree.sample\u001b[39m\u001b[34m(self, shape, force_inactive, force_active)\u001b[39m\n\u001b[32m     84\u001b[39m         sample.append((is_active * torch.rand(\u001b[32m1\u001b[39m)))\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mutually_exclusive_children:\n\u001b[32m     87\u001b[39m     active_child = (\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m         np.random.choice(\u001b[38;5;28mself\u001b[39m.children, p=\u001b[38;5;28mself\u001b[39m.child_probs)\n\u001b[32m     89\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m is_active\n\u001b[32m     90\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     91\u001b[39m     )\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children:\n\u001b[32m     94\u001b[39m     child_force_inactive = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(is_active) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m     95\u001b[39m         \u001b[38;5;28mself\u001b[39m.mutually_exclusive_children \u001b[38;5;129;01mand\u001b[39;00m child != active_child\n\u001b[32m     96\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy/random/mtrand.pyx:975\u001b[39m, in \u001b[36mnumpy.random.mtrand.RandomState.choice\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: probabilities do not sum to 1"
     ]
    }
   ],
   "source": [
    "\n",
    "generator = HierarchicalDataGenerator(**configs[\"exclusive_groups\"])\n",
    "dataset = generator.create_dataset(\n",
    "    batch_size=5, num_batches=2, device=\"cpu\"\n",
    ")\n",
    "\n",
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f35e3013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.13 | packaged by conda-forge | (main, Jun  4 2025, 14:48:01) [Clang 18.1.8 ]\n",
      "Executable: /usr/local/Caskroom/miniconda/base/envs/mech_int/bin/python\n",
      "Torch: 2.2.2 /usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/torch/__init__.py\n",
      "NumPy: 1.26.4 /usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/numpy/__init__.py\n",
      "Matplotlib: 3.10.5 /usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/matplotlib/__init__.py\n",
      "JSON: /usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/json/__init__.py\n",
      "Current working directory: /Users/kkumbier/github/matryoshka-saes/notebooks\n",
      "sys.path:\n",
      "/Users/kkumbier/github/matryoshka-saes/notebooks\n",
      "/Users/kkumbier/github/persisters/scripts\n",
      "/Users/kkumbier/github/als_coach\n",
      "/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python311.zip\n",
      "/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11\n",
      "/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/lib-dynload\n",
      "\n",
      "/usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages\n",
      "\n",
      "Checking for duplicate C extensions...\n",
      "torch found at:\n",
      "   /usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/torch/__init__.py\n",
      "numpy found at:\n",
      "   /usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/numpy/__init__.py\n",
      "matplotlib found at:\n",
      "   /usr/local/Caskroom/miniconda/base/envs/mech_int/lib/python3.11/site-packages/matplotlib/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib.util\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import json\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Executable:\", sys.executable)\n",
    "print(\"Torch:\", torch.__version__, torch.__file__)\n",
    "print(\"NumPy:\", np.__version__, np.__file__)\n",
    "print(\"Matplotlib:\", matplotlib.__version__, matplotlib.__file__)\n",
    "print(\"JSON:\", json.__file__)\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"sys.path:\")\n",
    "for p in sys.path: print(p)\n",
    "print(\"\\nChecking for duplicate C extensions...\")\n",
    "def find_duplicate_modules(module_name):\n",
    "    found = []\n",
    "    for p in sys.path:\n",
    "        try:\n",
    "            spec = importlib.util.find_spec(module_name, [p])\n",
    "            if spec and spec.origin and spec.origin not in found:\n",
    "                found.append(spec.origin)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return found\n",
    "for mod in [\"torch\", \"numpy\", \"matplotlib\"]:\n",
    "    paths = find_duplicate_modules(mod)\n",
    "    print(f\"{mod} found at:\")\n",
    "    for path in paths: print(\"  \", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a1e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generators for both configurations\n",
    "generators = {}\n",
    "datasets = {}\n",
    "feature_directions = {}\n",
    "\n",
    "for name, config in configs.items():\n",
    "    print(f\"\\nGenerating dataset for {name}...\")\n",
    "    \n",
    "    # Create the generator\n",
    "    generator = HierarchicalDataGenerator(**config)\n",
    "    generators[name] = generator\n",
    "\n",
    "    # Generate a dataset\n",
    "    X, feature_activations = generator.create_dataset()\n",
    "    \n",
    "    datasets[name] = {\n",
    "        'X': X,\n",
    "        'feature_activations': feature_activations,\n",
    "        'generator': generator\n",
    "    }\n",
    "    \n",
    "    print(f\"  Generated data shape: {X.shape}\")\n",
    "    print(f\"  Number of feature types: {len(feature_activations)}\")\n",
    "    print(f\"  Feature activation shapes: {[f'Level {i}: {act.shape}' for i, act in enumerate(feature_activations)]}\")\n",
    "    \n",
    "    # # Store feature directions for analysis\n",
    "    # feature_directions[name] = {\n",
    "    #     'orthogonal': generator.orthogonal_directions,\n",
    "    #     'correlated': generator.correlated_directions if hasattr(generator, 'correlated_directions') else None\n",
    "    # }\n",
    "\n",
    "print(\"\\nDataset generation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d0c024",
   "metadata": {},
   "source": [
    "## 4. Data Visualization: Generated Dataset Heatmaps\n",
    "\n",
    "Let's visualize the generated data matrices to understand the overall structure and patterns in our hierarchical datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e733a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmaps for generated data\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "for idx, (name, data) in enumerate(datasets.items()):\n",
    "    X = data['X'].detach().numpy() if torch.is_tensor(data['X']) else data['X']\n",
    "    \n",
    "    # Create heatmap\n",
    "    im = axes[idx].imshow(X[:50].T, aspect='auto', cmap='RdBu_r', interpolation='nearest')\n",
    "    axes[idx].set_title(f'{name.replace(\"_\", \" \").title()} - Generated Data\\n(First 50 samples)', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Sample Index')\n",
    "    axes[idx].set_ylabel('Feature Dimension')\n",
    "    \n",
    "    # Add colorbar\n",
    "    plt.colorbar(im, ax=axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print data statistics\n",
    "print(\"\\nData Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "for name, data in datasets.items():\n",
    "    X = data['X'].detach().numpy() if torch.is_tensor(data['X']) else data['X']\n",
    "    print(f\"\\n{name.upper()}:\")\n",
    "    print(f\"  Shape: {X.shape}\")\n",
    "    print(f\"  Mean: {X.mean():.4f}\")\n",
    "    print(f\"  Std: {X.std():.4f}\")\n",
    "    print(f\"  Min: {X.min():.4f}\")\n",
    "    print(f\"  Max: {X.max():.4f}\")\n",
    "    print(f\"  Non-zero elements: {np.count_nonzero(X)} / {X.size} ({100 * np.count_nonzero(X) / X.size:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99279885",
   "metadata": {},
   "source": [
    "## 5. Feature Activation Analysis\n",
    "\n",
    "Now let's examine the hierarchical feature activations to understand how features are activated at different levels of the tree structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001f9d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature activations for both configurations\n",
    "for name, data in datasets.items():\n",
    "    feature_activations = data['feature_activations']\n",
    "    \n",
    "    print(f\"\\n{name.upper()} - Feature Activation Analysis:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create subplots for each level\n",
    "    n_levels = len(feature_activations)\n",
    "    if n_levels > 0:\n",
    "        fig, axes = plt.subplots(1, n_levels, figsize=(5 * n_levels, 6))\n",
    "        if n_levels == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for level, activations in enumerate(feature_activations):\n",
    "            if torch.is_tensor(activations):\n",
    "                activations = activations.detach().numpy()\n",
    "            \n",
    "            # Show first 50 samples for clarity\n",
    "            display_activations = activations[:50]\n",
    "            \n",
    "            im = axes[level].imshow(display_activations.T, aspect='auto', cmap='Blues', interpolation='nearest')\n",
    "            axes[level].set_title(f'Level {level} Activations\\n({activations.shape[1]} features)', fontweight='bold')\n",
    "            axes[level].set_xlabel('Sample Index')\n",
    "            axes[level].set_ylabel('Feature Index')\n",
    "            plt.colorbar(im, ax=axes[level])\n",
    "            \n",
    "            # Print statistics\n",
    "            print(f\"  Level {level}:\")\n",
    "            print(f\"    Shape: {activations.shape}\")\n",
    "            print(f\"    Active features per sample (mean): {activations.sum(axis=1).mean():.2f}\")\n",
    "            print(f\"    Activation probability per feature: {activations.mean(axis=0).mean():.4f}\")\n",
    "            print(f\"    Non-zero activations: {np.count_nonzero(activations)} / {activations.size} ({100 * np.count_nonzero(activations) / activations.size:.2f}%)\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"  No feature activations found!\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e451f7",
   "metadata": {},
   "source": [
    "## 6. Feature Direction Analysis\n",
    "\n",
    "Let's analyze the feature directions (both orthogonal and correlated) to understand the geometric structure of our feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac74727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature directions for both configurations\n",
    "for name, directions in feature_directions.items():\n",
    "    print(f\"\\n{name.upper()} - Feature Direction Analysis:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Analyze orthogonal directions\n",
    "    if directions['orthogonal'] is not None:\n",
    "        ortho_dirs = directions['orthogonal']\n",
    "        if torch.is_tensor(ortho_dirs):\n",
    "            ortho_dirs = ortho_dirs.detach().numpy()\n",
    "        \n",
    "        print(f\"Orthogonal directions shape: {ortho_dirs.shape}\")\n",
    "        \n",
    "        # Visualize orthogonal directions\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Heatmap of directions\n",
    "        plt.subplot(1, 2, 1)\n",
    "        im1 = plt.imshow(ortho_dirs.T, aspect='auto', cmap='RdBu_r', interpolation='nearest')\n",
    "        plt.title(f'{name.replace(\"_\", \" \").title()}\\nOrthogonal Feature Directions', fontweight='bold')\n",
    "        plt.xlabel('Input Dimension')\n",
    "        plt.ylabel('Feature Index')\n",
    "        plt.colorbar(im1)\n",
    "        \n",
    "        # Compute and show correlation matrix of directions\n",
    "        plt.subplot(1, 2, 2)\n",
    "        correlation_matrix = np.corrcoef(ortho_dirs)\n",
    "        im2 = plt.imshow(correlation_matrix, cmap='RdBu_r', vmin=-1, vmax=1, interpolation='nearest')\n",
    "        plt.title('Feature Direction Correlations\\n(Should be near-orthogonal)', fontweight='bold')\n",
    "        plt.xlabel('Feature Index')\n",
    "        plt.ylabel('Feature Index')\n",
    "        plt.colorbar(im2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Statistics\n",
    "        print(f\"  Direction magnitudes (mean ± std): {np.linalg.norm(ortho_dirs, axis=1).mean():.4f} ± {np.linalg.norm(ortho_dirs, axis=1).std():.4f}\")\n",
    "        \n",
    "        # Check orthogonality\n",
    "        dot_products = []\n",
    "        n_features = ortho_dirs.shape[0]\n",
    "        for i in range(n_features):\n",
    "            for j in range(i+1, n_features):\n",
    "                dot_products.append(np.dot(ortho_dirs[i], ortho_dirs[j]))\n",
    "        \n",
    "        if dot_products:\n",
    "            mean_dot = np.mean(np.abs(dot_products))\n",
    "            print(f\"  Mean absolute dot product (orthogonality check): {mean_dot:.6f} (closer to 0 = more orthogonal)\")\n",
    "        \n",
    "    # Analyze correlated directions if they exist\n",
    "    if directions['correlated'] is not None:\n",
    "        corr_dirs = directions['correlated']\n",
    "        if torch.is_tensor(corr_dirs):\n",
    "            corr_dirs = corr_dirs.detach().numpy()\n",
    "        \n",
    "        print(f\"Correlated directions shape: {corr_dirs.shape}\")\n",
    "        \n",
    "        # Similar analysis for correlated directions\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        im1 = plt.imshow(corr_dirs.T, aspect='auto', cmap='RdBu_r', interpolation='nearest')\n",
    "        plt.title(f'{name.replace(\"_\", \" \").title()}\\nCorrelated Feature Directions', fontweight='bold')\n",
    "        plt.xlabel('Input Dimension')\n",
    "        plt.ylabel('Feature Index')\n",
    "        plt.colorbar(im1)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        correlation_matrix = np.corrcoef(corr_dirs)\n",
    "        im2 = plt.imshow(correlation_matrix, cmap='RdBu_r', vmin=-1, vmax=1, interpolation='nearest')\n",
    "        plt.title('Correlated Direction Correlations', fontweight='bold')\n",
    "        plt.xlabel('Feature Index')\n",
    "        plt.ylabel('Feature Index')\n",
    "        plt.colorbar(im2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"  Correlated direction magnitudes (mean ± std): {np.linalg.norm(corr_dirs, axis=1).mean():.4f} ± {np.linalg.norm(corr_dirs, axis=1).std():.4f}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f17cb3",
   "metadata": {},
   "source": [
    "## 7. Comparative Analysis: Exclusive Groups vs Simple Hierarchy\n",
    "\n",
    "Let's compare the two configurations directly to understand their differences in structure and behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative analysis between configurations\n",
    "print(\"COMPARATIVE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compare basic properties\n",
    "config_names = list(configs.keys())\n",
    "name1, name2 = config_names[0], config_names[1]\n",
    "\n",
    "print(f\"\\nConfiguration Comparison:\")\n",
    "print(f\"{'Property':<25} {'Exclusive Groups':<20} {'Simple Hierarchy':<20}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for prop in ['input_dim', 'n_samples', 'correlation_type', 'feature_correlation']:\n",
    "    val1 = configs[name1].get(prop, 'N/A')\n",
    "    val2 = configs[name2].get(prop, 'N/A')\n",
    "    print(f\"{prop:<25} {str(val1):<20} {str(val2):<20}\")\n",
    "\n",
    "# Compare data characteristics\n",
    "print(f\"\\nData Characteristics:\")\n",
    "print(f\"{'Metric':<25} {'Exclusive Groups':<20} {'Simple Hierarchy':<20}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "data1 = datasets[name1]['X'].detach().numpy() if torch.is_tensor(datasets[name1]['X']) else datasets[name1]['X']\n",
    "data2 = datasets[name2]['X'].detach().numpy() if torch.is_tensor(datasets[name2]['X']) else datasets[name2]['X']\n",
    "\n",
    "metrics = {\n",
    "    'Data shape': [str(data1.shape), str(data2.shape)],\n",
    "    'Mean activation': [f\"{data1.mean():.4f}\", f\"{data2.mean():.4f}\"],\n",
    "    'Std activation': [f\"{data1.std():.4f}\", f\"{data2.std():.4f}\"],\n",
    "    'Sparsity (% zeros)': [f\"{100*(1-np.count_nonzero(data1)/data1.size):.1f}%\", \n",
    "                          f\"{100*(1-np.count_nonzero(data2)/data2.size):.1f}%\"]\n",
    "}\n",
    "\n",
    "for metric, values in metrics.items():\n",
    "    print(f\"{metric:<25} {values[0]:<20} {values[1]:<20}\")\n",
    "\n",
    "# Compare feature activation patterns\n",
    "print(f\"\\nFeature Activation Patterns:\")\n",
    "print(f\"{'Level':<10} {'Exclusive Groups':<30} {'Simple Hierarchy':<30}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "max_levels = max(len(datasets[name1]['feature_activations']), len(datasets[name2]['feature_activations']))\n",
    "\n",
    "for level in range(max_levels):\n",
    "    act1 = datasets[name1]['feature_activations'][level] if level < len(datasets[name1]['feature_activations']) else None\n",
    "    act2 = datasets[name2]['feature_activations'][level] if level < len(datasets[name2]['feature_activations']) else None\n",
    "    \n",
    "    if act1 is not None:\n",
    "        act1_np = act1.detach().numpy() if torch.is_tensor(act1) else act1\n",
    "        act1_desc = f\"Shape: {act1_np.shape}, Sparsity: {100*(1-np.count_nonzero(act1_np)/act1_np.size):.1f}%\"\n",
    "    else:\n",
    "        act1_desc = \"No activations\"\n",
    "        \n",
    "    if act2 is not None:\n",
    "        act2_np = act2.detach().numpy() if torch.is_tensor(act2) else act2\n",
    "        act2_desc = f\"Shape: {act2_np.shape}, Sparsity: {100*(1-np.count_nonzero(act2_np)/act2_np.size):.1f}%\"\n",
    "    else:\n",
    "        act2_desc = \"No activations\"\n",
    "    \n",
    "    print(f\"{level:<10} {act1_desc:<30} {act2_desc:<30}\")\n",
    "\n",
    "# Side-by-side visualization\n",
    "print(f\"\\nSide-by-side Data Visualization:\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Top row: raw data comparison\n",
    "for idx, (name, data) in enumerate(datasets.items()):\n",
    "    X = data['X'].detach().numpy() if torch.is_tensor(data['X']) else data['X']\n",
    "    im = axes[0, idx].imshow(X[:100].T, aspect='auto', cmap='RdBu_r', interpolation='nearest')\n",
    "    axes[0, idx].set_title(f'{name.replace(\"_\", \" \").title()}\\nGenerated Data (First 100 samples)', fontweight='bold')\n",
    "    axes[0, idx].set_xlabel('Sample Index')\n",
    "    axes[0, idx].set_ylabel('Feature Dimension')\n",
    "    plt.colorbar(im, ax=axes[0, idx])\n",
    "\n",
    "# Bottom row: feature activations (level 0 if available)\n",
    "for idx, (name, data) in enumerate(datasets.items()):\n",
    "    if len(data['feature_activations']) > 0:\n",
    "        activations = data['feature_activations'][0]\n",
    "        if torch.is_tensor(activations):\n",
    "            activations = activations.detach().numpy()\n",
    "        im = axes[1, idx].imshow(activations[:100].T, aspect='auto', cmap='Blues', interpolation='nearest')\n",
    "        axes[1, idx].set_title(f'{name.replace(\"_\", \" \").title()}\\nLevel 0 Feature Activations', fontweight='bold')\n",
    "        axes[1, idx].set_xlabel('Sample Index')\n",
    "        axes[1, idx].set_ylabel('Feature Index')\n",
    "        plt.colorbar(im, ax=axes[1, idx])\n",
    "    else:\n",
    "        axes[1, idx].text(0.5, 0.5, 'No feature activations\\navailable', \n",
    "                         ha='center', va='center', transform=axes[1, idx].transAxes, fontsize=12)\n",
    "        axes[1, idx].set_title(f'{name.replace(\"_\", \" \").title()}\\nNo Feature Activations', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mech_int",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
