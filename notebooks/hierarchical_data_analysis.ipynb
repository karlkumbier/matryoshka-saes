{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2034d4b3",
   "metadata": {},
   "source": [
    "# Hierarchical Data Generator Analysis\n",
    "\n",
    "This notebook demonstrates the generation and analysis of hierarchical sparse data using two different tree configurations:\n",
    "\n",
    "1. **Simple Hierarchy**: A basic two-level tree structure with hierarchical dependencies\n",
    "2. **Exclusive Groups**: A tree structure with mutually exclusive children \n",
    "\n",
    "We'll generate synthetic datasets for both configurations and create comprehensive visualizations including:\n",
    "- Feature activation patterns\n",
    "- Data vector representations  \n",
    "- Feature direction vectors\n",
    "- Statistical properties and dependencies\n",
    "\n",
    "The analysis showcases how different tree structures create distinct patterns in the generated data, which can be used to test Sparse Autoencoders (SAEs) under various hierarchical constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a7b73a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8cc3230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1113b2c10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import our custom modules\n",
    "sys.path.append(\"/Users/kkumbier/github/matryoshka-saes/\")\n",
    "from data_generator import HierarchicalDataGenerator\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cab4a05",
   "metadata": {},
   "source": [
    "## 2. Load Tree Configurations\n",
    "\n",
    "We'll load the two tree configurations we want to analyze:\n",
    "- **Simple Hierarchy**: A basic hierarchical structure with standard parameters\n",
    "- **Exclusive Groups**: A configuration with mutually exclusive feature groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d72a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configurations:\n",
      "{\n",
      "  \"exclusive_groups\": {\n",
      "    \"tree_config\": {\n",
      "      \"active_prob\": 1.0,\n",
      "      \"is_read_out\": false,\n",
      "      \"children\": [\n",
      "        {\n",
      "          \"active_prob\": 0.3,\n",
      "          \"is_read_out\": true,\n",
      "          \"mutually_exclusive_children\": true,\n",
      "          \"children\": [\n",
      "            {\n",
      "              \"active_prob\": 0.4,\n",
      "              \"is_read_out\": true\n",
      "            },\n",
      "            {\n",
      "              \"active_prob\": 0.6,\n",
      "              \"is_read_out\": true\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    \"d_model\": 128,\n",
      "    \"feature_correlation\": 0.1,\n",
      "    \"orthogonal_features\": true,\n",
      "    \"feature_scale_variation\": 0.1,\n",
      "    \"random_seed\": 123\n",
      "  },\n",
      "  \"simple_hierarchy\": {\n",
      "    \"tree_config\": {\n",
      "      \"active_prob\": 1.0,\n",
      "      \"is_read_out\": false,\n",
      "      \"children\": [\n",
      "        {\n",
      "          \"active_prob\": 0.2,\n",
      "          \"is_read_out\": true,\n",
      "          \"children\": [\n",
      "            {\n",
      "              \"active_prob\": 0.8,\n",
      "              \"is_read_out\": true\n",
      "            },\n",
      "            {\n",
      "              \"active_prob\": 0.6,\n",
      "              \"is_read_out\": true\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    \"d_model\": 256,\n",
      "    \"feature_correlation\": 0.0,\n",
      "    \"orthogonal_features\": true,\n",
      "    \"feature_scale_variation\": 0.05,\n",
      "    \"random_seed\": 42\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Define the tree parameter directory\n",
    "tree_params_dir = \"/Users/kkumbier/github/matryoshka-saes/tree_params\"\n",
    "\n",
    "# Load the two configurations we want to analyze\n",
    "configs = {}\n",
    "\n",
    "# Load exclusive groups configuration (full parameters)\n",
    "with open(os.path.join(tree_params_dir, \"exclusive_params.json\"), 'r') as f:\n",
    "    configs['exclusive_groups'] = json.load(f)\n",
    "\n",
    "# Load simple hierarchy configuration (full parameters)  \n",
    "with open(os.path.join(tree_params_dir, \"simple_params.json\"), 'r') as f:\n",
    "    configs['simple_hierarchy'] = json.load(f)\n",
    "\n",
    "\n",
    "print(\"Loaded configurations:\")\n",
    "print(json.dumps(configs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d12231",
   "metadata": {},
   "source": [
    "## 3. Generate Datasets for Both Configurations\n",
    "\n",
    "Now we'll create HierarchicalDataGenerator instances for each configuration and generate sample datasets to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "960d50a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "generator = HierarchicalDataGenerator(**configs[\"simple_hierarchy\"])\n",
    "#dataset = generator.create_dataset(\n",
    "#    batch_size=5, num_batches=2, device=\"cpu\"\n",
    "#)\n",
    "\n",
    "#dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e3013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib.util\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import json\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Executable:\", sys.executable)\n",
    "print(\"Torch:\", torch.__version__, torch.__file__)\n",
    "print(\"NumPy:\", np.__version__, np.__file__)\n",
    "print(\"Matplotlib:\", matplotlib.__version__, matplotlib.__file__)\n",
    "print(\"JSON:\", json.__file__)\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"sys.path:\")\n",
    "for p in sys.path: print(p)\n",
    "print(\"\\nChecking for duplicate C extensions...\")\n",
    "def find_duplicate_modules(module_name):\n",
    "    found = []\n",
    "    for p in sys.path:\n",
    "        try:\n",
    "            spec = importlib.util.find_spec(module_name, [p])\n",
    "            if spec and spec.origin and spec.origin not in found:\n",
    "                found.append(spec.origin)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return found\n",
    "for mod in [\"torch\", \"numpy\", \"matplotlib\"]:\n",
    "    paths = find_duplicate_modules(mod)\n",
    "    print(f\"{mod} found at:\")\n",
    "    for path in paths: print(\"  \", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a1e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generators for both configurations\n",
    "generators = {}\n",
    "datasets = {}\n",
    "feature_directions = {}\n",
    "\n",
    "for name, config in configs.items():\n",
    "    print(f\"\\nGenerating dataset for {name}...\")\n",
    "    \n",
    "    # Create the generator\n",
    "    generator = HierarchicalDataGenerator(**config)\n",
    "    generators[name] = generator\n",
    "\n",
    "    # Generate a dataset\n",
    "    X, feature_activations = generator.create_dataset()\n",
    "    \n",
    "    datasets[name] = {\n",
    "        'X': X,\n",
    "        'feature_activations': feature_activations,\n",
    "        'generator': generator\n",
    "    }\n",
    "    \n",
    "    print(f\"  Generated data shape: {X.shape}\")\n",
    "    print(f\"  Number of feature types: {len(feature_activations)}\")\n",
    "    print(f\"  Feature activation shapes: {[f'Level {i}: {act.shape}' for i, act in enumerate(feature_activations)]}\")\n",
    "    \n",
    "    # # Store feature directions for analysis\n",
    "    # feature_directions[name] = {\n",
    "    #     'orthogonal': generator.orthogonal_directions,\n",
    "    #     'correlated': generator.correlated_directions if hasattr(generator, 'correlated_directions') else None\n",
    "    # }\n",
    "\n",
    "print(\"\\nDataset generation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d0c024",
   "metadata": {},
   "source": [
    "## 4. Data Visualization: Generated Dataset Heatmaps\n",
    "\n",
    "Let's visualize the generated data matrices to understand the overall structure and patterns in our hierarchical datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e733a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmaps for generated data\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "for idx, (name, data) in enumerate(datasets.items()):\n",
    "    X = data['X'].detach().numpy() if torch.is_tensor(data['X']) else data['X']\n",
    "    \n",
    "    # Create heatmap\n",
    "    im = axes[idx].imshow(X[:50].T, aspect='auto', cmap='RdBu_r', interpolation='nearest')\n",
    "    axes[idx].set_title(f'{name.replace(\"_\", \" \").title()} - Generated Data\\n(First 50 samples)', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Sample Index')\n",
    "    axes[idx].set_ylabel('Feature Dimension')\n",
    "    \n",
    "    # Add colorbar\n",
    "    plt.colorbar(im, ax=axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print data statistics\n",
    "print(\"\\nData Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "for name, data in datasets.items():\n",
    "    X = data['X'].detach().numpy() if torch.is_tensor(data['X']) else data['X']\n",
    "    print(f\"\\n{name.upper()}:\")\n",
    "    print(f\"  Shape: {X.shape}\")\n",
    "    print(f\"  Mean: {X.mean():.4f}\")\n",
    "    print(f\"  Std: {X.std():.4f}\")\n",
    "    print(f\"  Min: {X.min():.4f}\")\n",
    "    print(f\"  Max: {X.max():.4f}\")\n",
    "    print(f\"  Non-zero elements: {np.count_nonzero(X)} / {X.size} ({100 * np.count_nonzero(X) / X.size:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99279885",
   "metadata": {},
   "source": [
    "## 5. Feature Activation Analysis\n",
    "\n",
    "Now let's examine the hierarchical feature activations to understand how features are activated at different levels of the tree structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001f9d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature activations for both configurations\n",
    "for name, data in datasets.items():\n",
    "    feature_activations = data['feature_activations']\n",
    "    \n",
    "    print(f\"\\n{name.upper()} - Feature Activation Analysis:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create subplots for each level\n",
    "    n_levels = len(feature_activations)\n",
    "    if n_levels > 0:\n",
    "        fig, axes = plt.subplots(1, n_levels, figsize=(5 * n_levels, 6))\n",
    "        if n_levels == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for level, activations in enumerate(feature_activations):\n",
    "            if torch.is_tensor(activations):\n",
    "                activations = activations.detach().numpy()\n",
    "            \n",
    "            # Show first 50 samples for clarity\n",
    "            display_activations = activations[:50]\n",
    "            \n",
    "            im = axes[level].imshow(display_activations.T, aspect='auto', cmap='Blues', interpolation='nearest')\n",
    "            axes[level].set_title(f'Level {level} Activations\\n({activations.shape[1]} features)', fontweight='bold')\n",
    "            axes[level].set_xlabel('Sample Index')\n",
    "            axes[level].set_ylabel('Feature Index')\n",
    "            plt.colorbar(im, ax=axes[level])\n",
    "            \n",
    "            # Print statistics\n",
    "            print(f\"  Level {level}:\")\n",
    "            print(f\"    Shape: {activations.shape}\")\n",
    "            print(f\"    Active features per sample (mean): {activations.sum(axis=1).mean():.2f}\")\n",
    "            print(f\"    Activation probability per feature: {activations.mean(axis=0).mean():.4f}\")\n",
    "            print(f\"    Non-zero activations: {np.count_nonzero(activations)} / {activations.size} ({100 * np.count_nonzero(activations) / activations.size:.2f}%)\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"  No feature activations found!\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e451f7",
   "metadata": {},
   "source": [
    "## 6. Feature Direction Analysis\n",
    "\n",
    "Let's analyze the feature directions (both orthogonal and correlated) to understand the geometric structure of our feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac74727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature directions for both configurations\n",
    "for name, directions in feature_directions.items():\n",
    "    print(f\"\\n{name.upper()} - Feature Direction Analysis:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Analyze orthogonal directions\n",
    "    if directions['orthogonal'] is not None:\n",
    "        ortho_dirs = directions['orthogonal']\n",
    "        if torch.is_tensor(ortho_dirs):\n",
    "            ortho_dirs = ortho_dirs.detach().numpy()\n",
    "        \n",
    "        print(f\"Orthogonal directions shape: {ortho_dirs.shape}\")\n",
    "        \n",
    "        # Visualize orthogonal directions\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Heatmap of directions\n",
    "        plt.subplot(1, 2, 1)\n",
    "        im1 = plt.imshow(ortho_dirs.T, aspect='auto', cmap='RdBu_r', interpolation='nearest')\n",
    "        plt.title(f'{name.replace(\"_\", \" \").title()}\\nOrthogonal Feature Directions', fontweight='bold')\n",
    "        plt.xlabel('Input Dimension')\n",
    "        plt.ylabel('Feature Index')\n",
    "        plt.colorbar(im1)\n",
    "        \n",
    "        # Compute and show correlation matrix of directions\n",
    "        plt.subplot(1, 2, 2)\n",
    "        correlation_matrix = np.corrcoef(ortho_dirs)\n",
    "        im2 = plt.imshow(correlation_matrix, cmap='RdBu_r', vmin=-1, vmax=1, interpolation='nearest')\n",
    "        plt.title('Feature Direction Correlations\\n(Should be near-orthogonal)', fontweight='bold')\n",
    "        plt.xlabel('Feature Index')\n",
    "        plt.ylabel('Feature Index')\n",
    "        plt.colorbar(im2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Statistics\n",
    "        print(f\"  Direction magnitudes (mean ± std): {np.linalg.norm(ortho_dirs, axis=1).mean():.4f} ± {np.linalg.norm(ortho_dirs, axis=1).std():.4f}\")\n",
    "        \n",
    "        # Check orthogonality\n",
    "        dot_products = []\n",
    "        n_features = ortho_dirs.shape[0]\n",
    "        for i in range(n_features):\n",
    "            for j in range(i+1, n_features):\n",
    "                dot_products.append(np.dot(ortho_dirs[i], ortho_dirs[j]))\n",
    "        \n",
    "        if dot_products:\n",
    "            mean_dot = np.mean(np.abs(dot_products))\n",
    "            print(f\"  Mean absolute dot product (orthogonality check): {mean_dot:.6f} (closer to 0 = more orthogonal)\")\n",
    "        \n",
    "    # Analyze correlated directions if they exist\n",
    "    if directions['correlated'] is not None:\n",
    "        corr_dirs = directions['correlated']\n",
    "        if torch.is_tensor(corr_dirs):\n",
    "            corr_dirs = corr_dirs.detach().numpy()\n",
    "        \n",
    "        print(f\"Correlated directions shape: {corr_dirs.shape}\")\n",
    "        \n",
    "        # Similar analysis for correlated directions\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        im1 = plt.imshow(corr_dirs.T, aspect='auto', cmap='RdBu_r', interpolation='nearest')\n",
    "        plt.title(f'{name.replace(\"_\", \" \").title()}\\nCorrelated Feature Directions', fontweight='bold')\n",
    "        plt.xlabel('Input Dimension')\n",
    "        plt.ylabel('Feature Index')\n",
    "        plt.colorbar(im1)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        correlation_matrix = np.corrcoef(corr_dirs)\n",
    "        im2 = plt.imshow(correlation_matrix, cmap='RdBu_r', vmin=-1, vmax=1, interpolation='nearest')\n",
    "        plt.title('Correlated Direction Correlations', fontweight='bold')\n",
    "        plt.xlabel('Feature Index')\n",
    "        plt.ylabel('Feature Index')\n",
    "        plt.colorbar(im2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"  Correlated direction magnitudes (mean ± std): {np.linalg.norm(corr_dirs, axis=1).mean():.4f} ± {np.linalg.norm(corr_dirs, axis=1).std():.4f}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f17cb3",
   "metadata": {},
   "source": [
    "## 7. Comparative Analysis: Exclusive Groups vs Simple Hierarchy\n",
    "\n",
    "Let's compare the two configurations directly to understand their differences in structure and behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative analysis between configurations\n",
    "print(\"COMPARATIVE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compare basic properties\n",
    "config_names = list(configs.keys())\n",
    "name1, name2 = config_names[0], config_names[1]\n",
    "\n",
    "print(f\"\\nConfiguration Comparison:\")\n",
    "print(f\"{'Property':<25} {'Exclusive Groups':<20} {'Simple Hierarchy':<20}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for prop in ['input_dim', 'n_samples', 'correlation_type', 'feature_correlation']:\n",
    "    val1 = configs[name1].get(prop, 'N/A')\n",
    "    val2 = configs[name2].get(prop, 'N/A')\n",
    "    print(f\"{prop:<25} {str(val1):<20} {str(val2):<20}\")\n",
    "\n",
    "# Compare data characteristics\n",
    "print(f\"\\nData Characteristics:\")\n",
    "print(f\"{'Metric':<25} {'Exclusive Groups':<20} {'Simple Hierarchy':<20}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "data1 = datasets[name1]['X'].detach().numpy() if torch.is_tensor(datasets[name1]['X']) else datasets[name1]['X']\n",
    "data2 = datasets[name2]['X'].detach().numpy() if torch.is_tensor(datasets[name2]['X']) else datasets[name2]['X']\n",
    "\n",
    "metrics = {\n",
    "    'Data shape': [str(data1.shape), str(data2.shape)],\n",
    "    'Mean activation': [f\"{data1.mean():.4f}\", f\"{data2.mean():.4f}\"],\n",
    "    'Std activation': [f\"{data1.std():.4f}\", f\"{data2.std():.4f}\"],\n",
    "    'Sparsity (% zeros)': [f\"{100*(1-np.count_nonzero(data1)/data1.size):.1f}%\", \n",
    "                          f\"{100*(1-np.count_nonzero(data2)/data2.size):.1f}%\"]\n",
    "}\n",
    "\n",
    "for metric, values in metrics.items():\n",
    "    print(f\"{metric:<25} {values[0]:<20} {values[1]:<20}\")\n",
    "\n",
    "# Compare feature activation patterns\n",
    "print(f\"\\nFeature Activation Patterns:\")\n",
    "print(f\"{'Level':<10} {'Exclusive Groups':<30} {'Simple Hierarchy':<30}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "max_levels = max(len(datasets[name1]['feature_activations']), len(datasets[name2]['feature_activations']))\n",
    "\n",
    "for level in range(max_levels):\n",
    "    act1 = datasets[name1]['feature_activations'][level] if level < len(datasets[name1]['feature_activations']) else None\n",
    "    act2 = datasets[name2]['feature_activations'][level] if level < len(datasets[name2]['feature_activations']) else None\n",
    "    \n",
    "    if act1 is not None:\n",
    "        act1_np = act1.detach().numpy() if torch.is_tensor(act1) else act1\n",
    "        act1_desc = f\"Shape: {act1_np.shape}, Sparsity: {100*(1-np.count_nonzero(act1_np)/act1_np.size):.1f}%\"\n",
    "    else:\n",
    "        act1_desc = \"No activations\"\n",
    "        \n",
    "    if act2 is not None:\n",
    "        act2_np = act2.detach().numpy() if torch.is_tensor(act2) else act2\n",
    "        act2_desc = f\"Shape: {act2_np.shape}, Sparsity: {100*(1-np.count_nonzero(act2_np)/act2_np.size):.1f}%\"\n",
    "    else:\n",
    "        act2_desc = \"No activations\"\n",
    "    \n",
    "    print(f\"{level:<10} {act1_desc:<30} {act2_desc:<30}\")\n",
    "\n",
    "# Side-by-side visualization\n",
    "print(f\"\\nSide-by-side Data Visualization:\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Top row: raw data comparison\n",
    "for idx, (name, data) in enumerate(datasets.items()):\n",
    "    X = data['X'].detach().numpy() if torch.is_tensor(data['X']) else data['X']\n",
    "    im = axes[0, idx].imshow(X[:100].T, aspect='auto', cmap='RdBu_r', interpolation='nearest')\n",
    "    axes[0, idx].set_title(f'{name.replace(\"_\", \" \").title()}\\nGenerated Data (First 100 samples)', fontweight='bold')\n",
    "    axes[0, idx].set_xlabel('Sample Index')\n",
    "    axes[0, idx].set_ylabel('Feature Dimension')\n",
    "    plt.colorbar(im, ax=axes[0, idx])\n",
    "\n",
    "# Bottom row: feature activations (level 0 if available)\n",
    "for idx, (name, data) in enumerate(datasets.items()):\n",
    "    if len(data['feature_activations']) > 0:\n",
    "        activations = data['feature_activations'][0]\n",
    "        if torch.is_tensor(activations):\n",
    "            activations = activations.detach().numpy()\n",
    "        im = axes[1, idx].imshow(activations[:100].T, aspect='auto', cmap='Blues', interpolation='nearest')\n",
    "        axes[1, idx].set_title(f'{name.replace(\"_\", \" \").title()}\\nLevel 0 Feature Activations', fontweight='bold')\n",
    "        axes[1, idx].set_xlabel('Sample Index')\n",
    "        axes[1, idx].set_ylabel('Feature Index')\n",
    "        plt.colorbar(im, ax=axes[1, idx])\n",
    "    else:\n",
    "        axes[1, idx].text(0.5, 0.5, 'No feature activations\\navailable', \n",
    "                         ha='center', va='center', transform=axes[1, idx].transAxes, fontsize=12)\n",
    "        axes[1, idx].set_title(f'{name.replace(\"_\", \" \").title()}\\nNo Feature Activations', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mech_int",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
